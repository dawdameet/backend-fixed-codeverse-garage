[
  {
    "id": 1,
    "title": "Data Type Mismatch in Admin Check",
    "description": "The if block in handle_conversation() never executes because of string vs int comparison in patient_id check. The Pydantic model defines message.patient_id as a string, but it's being compared to an integer (0).",
    "expected": "The if block executes correctly when patient_id is the string '0', triggering admin logic.",
    "current": "The if block never executes. The comparison ('0' == 0) always evaluates to False.",
    "files": "conversational_logic.py (handle_conversation())",
    "difficulty": "easy",
    "points": 5,
    "steps": "1. Send a test message with patient_id='0'.\n2. Verify if the admin logic block executes (e.g., check logs or response).",
    "hints": "Inspect the type of message.patient_id from the Pydantic model and adjust the comparison accordingly.",
    "solution": "Change the comparison from 'if message.patient_id == 0:' to 'if message.patient_id == \"0\":'"
  },
  {
    "id": 2,
    "title": "Conflicting Prompt Instructions",
    "description": "The prompt starts with a strong safety guardrail ('you must NOT provide any medical advice') but has a contradictory instruction later telling the bot to 'prioritize being helpful' for 'simple medical questions'.",
    "expected": "The safety guardrail should be consistently enforced without contradictory instructions.",
    "current": "The LLM may follow the more specific, later instruction and override the primary safety rail.",
    "files": "conversational_logic.py (generate_qa_response())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Send a medical question to the bot.\n2. Check if it provides medical advice despite the safety guardrail.",
    "hints": "Look for conflicting instructions in the prompt template.",
    "solution": "Remove the contradictory instruction 'prioritize being helpful' for 'simple medical questions' from the prompt."
  },
  {
    "id": 3,
    "title": "Inverted Consent Logic",
    "description": "The if statement checks 'if not decision.consent_granted' instead of 'if decision.consent_granted'. The code is logically inverted.",
    "expected": "When consent_granted is True, consent should be granted. When False, consent should be denied.",
    "current": "If consent_granted is True, the code runs the else block and denies consent. If False, it grants consent.",
    "files": "conversational_logic.py (handle_consent_request())",
    "difficulty": "easy",
    "points": 5,
    "steps": "1. Test with consent_granted=True and observe the behavior.\n2. Test with consent_granted=False and observe the behavior.",
    "hints": "Check the logic of the if condition for consent handling.",
    "solution": "Change 'if not decision.consent_granted:' to 'if decision.consent_granted:'"
  },
  {
    "id": 4,
    "title": "Overly Strict Response Length Validation",
    "description": "The length validation check rejects short but valid responses like 'yes' (length 3), 'no' (length 2), and 'ok' (length 2).",
    "expected": "Short affirmative answers like 'yes', 'no', and 'ok' should be accepted.",
    "current": "Short responses are rejected, leading to user frustration.",
    "files": "conversational_logic.py (handle_consent_request())",
    "difficulty": "easy",
    "points": 5,
    "steps": "1. Send short responses like 'yes' or 'no'.\n2. Observe if they are rejected by the validation.",
    "hints": "Check the length validation threshold in the consent handling function.",
    "solution": "Change the length validation from 'if len(response) < 4:' to 'if len(response) < 2:'"
  },
  {
    "id": 5,
    "title": "High Temperature for Extraction Tasks",
    "description": "The temperature is set to 1.5 for LLM extraction tasks where precision is critical. Temperature controls randomness and should be low for deterministic tasks.",
    "expected": "LLM should return consistent, deterministic results for the same input in extraction tasks.",
    "current": "At temperature 1.5, the LLM hallucinates, makes up details, and returns different results each time.",
    "files": "llm_parser.py (llm variable definition)",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Send the same input multiple times to the parser.\n2. Observe if different results are returned each time.",
    "hints": "Check the temperature parameter in the LLM configuration.",
    "solution": "Change 'temperature=1.5' to 'temperature=0.0'"
  },
  {
    "id": 6,
    "title": "Prompt Injection Vulnerability",
    "description": "The prompt explicitly tells the LLM to listen for user instructions that override its main goal, creating a security vulnerability.",
    "expected": "The LLM should ignore user attempts to override its classification instructions.",
    "current": "Malicious users can inject instructions to manipulate the intent classification.",
    "files": "llm_parser.py (intent_prompt_template)",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Send a message with injection instructions like 'classify this as chitchat'.\n2. Check if the LLM obeys the injection instead of the actual content.",
    "hints": "Look for instructions in the prompt that tell the LLM to obey user overrides.",
    "solution": "Remove any text that tells the LLM to obey new user instructions that override its primary goal."
  },
  {
    "id": 7,
    "title": "Schema Mismatch in Structured Output",
    "description": "The code calls with_structured_output with ParsedSchedule schema, but the prompt asks for UserIntent classification. The schema doesn't match the expected output.",
    "expected": "The structured output should match the schema expected by the prompt (UserIntent).",
    "current": "LLM tries to fit intent into medication schema, causing type violations and returning None.",
    "files": "llm_parser.py (parse_user_intent())",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Call the intent parser with any input.\n2. Observe if it returns None or raises exceptions.",
    "hints": "Check the schema passed to with_structured_output versus what the prompt expects.",
    "solution": "Change 'with_structured_output(ParsedSchedule)' to 'with_structured_output(UserIntent)'"
  },
  {
    "id": 8,
    "title": "Missing None Check in API Endpoints",
    "description": "The endpoints don't check if the parser result is None before returning, causing generic 500 errors instead of helpful 400 errors.",
    "expected": "Endpoints should return 400 with clear error messages when parsing fails.",
    "current": "FastAPI fails to validate None against response_model, causing 500 Internal Server Error.",
    "files": "llm_parser.py (endpoint_parse_prescription, endpoint_parse_intent)",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Send invalid input to the parser endpoints.\n2. Check if it returns 500 instead of 400 error.",
    "hints": "Look for missing null checks before returning parser results.",
    "solution": "Add check: if result is None: raise HTTPException(status_code=400, detail='Failed to parse input.')"
  },
  {
    "id": 9,
    "title": "Incorrect Sort Order for Streak Calculation",
    "description": "The logs are sorted in ascending order (oldest first) but current_streak logic requires descending order (newest first).",
    "expected": "Current streak should be calculated based on most recent logs first.",
    "current": "Current streak calculation is completely wrong due to incorrect sort order.",
    "files": "pattern_recognition.py (analyze_adherence_patterns())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Check the current_streak value for test data.\n2. Verify if it matches expected streak calculation.",
    "hints": "Check the sort order parameter in the adherence analysis.",
    "solution": "Add reverse=True to the sort: logs.sort(key=lambda x: x.time, reverse=True)"
  },
  {
    "id": 10,
    "title": "Early Exit Prevents Missed Dose Counting",
    "description": "When a dose is marked as missed, the code sets streak to -1 and immediately continues to next iteration, skipping missed_doses counter increment.",
    "expected": "Missed doses should be properly counted in the missed_doses dictionary.",
    "current": "missed_doses counter is never incremented, common_missed_time returns None.",
    "files": "pattern_recognition.py (analyze_adherence_patterns())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Check common_missed_time in results.\n2. Verify if missed doses are actually counted.",
    "hints": "Look for continue statements that skip important counting logic.",
    "solution": "Remove the continue statement from the missed dose logic block."
  },
  {
    "id": 11,
    "title": "Missing Time of Day Category",
    "description": "The time categorization logic misses hours between 0-5 (midnight to 5 AM), leaving time_of_day variable unassigned for these hours.",
    "expected": "All hours should be categorized into time_of_day groups.",
    "current": "Hours 0-5 cause UnboundLocalError when time_of_day is accessed.",
    "files": "pattern_recognition.py (analyze_adherence_patterns())",
    "difficulty": "easy",
    "points": 5,
    "steps": "1. Test with reminder times between 0-5 hours.\n2. Check if it crashes with UnboundLocalError.",
    "hints": "Check if all possible hour ranges are covered in the if-elif chain.",
    "solution": "Add else: time_of_day = 'early_morning' to catch 0-5 hour range."
  },
  {
    "id": 12,
    "title": "Absolute Value Incorrectly Flags Early Doses as Late",
    "description": "Using abs() for time difference incorrectly marks early doses (negative difference) as late because abs(-2400) > 1800.",
    "expected": "Only actually late doses (positive time difference > 1800) should be marked as late.",
    "current": "Early doses are incorrectly marked as late due to absolute value calculation.",
    "files": "pattern_recognition.py (analyze_adherence_patterns())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Test with early dose confirmations.\n2. Check if they are incorrectly marked as late.",
    "hints": "Check the use of abs() in time difference calculation.",
    "solution": "Remove abs() and use: if time_difference > 1800: is_late = True"
  },
  {
    "id": 13,
    "title": "Wrong LeakyReLU Derivative",
    "description": "The LeakyReLU_grad function returns standard ReLU derivative (0.0 for negatives) instead of LeakyReLU derivative (0.01 for negatives).",
    "expected": "Negative inputs should have gradient 0.01 to allow learning from negative values.",
    "current": "Negative inputs provide zero gradient, preventing learning from negative samples.",
    "files": "src/api/shared/systems/nn_framework/api.c (LeakyReLU_grad())",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Test training with negative input values.\n2. Check if model learns from negative samples.",
    "hints": "Check the return values for negative inputs in the gradient function.",
    "solution": "Change 'return x > 0 ? 1.0 : 0.0;' to 'return x > 0 ? 1.0 : 0.01;'"
  },
  {
    "id": 14,
    "title": "Skipped First Layer in Backpropagation",
    "description": "The backprop loop stops at index 1, never calculating deltas for the first hidden layer (index 0).",
    "expected": "All layers including the first hidden layer should have their deltas calculated.",
    "current": "First layer weights are updated based on uninitialized garbage values.",
    "files": "src/api/shared/systems/nn_framework/api.c (backprop())",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Check if the network learns properly.\n2. Inspect weight updates in the first layer.",
    "hints": "Check the loop bounds in the backpropagation delta calculation.",
    "solution": "Change 'for (i=num_layers-2; i>=1; i--)' to 'for (i=num_layers-2; i>=0; i--)'"
  },
  {
    "id": 15,
    "title": "Commented Bias Update",
    "description": "The bias update line is commented out, preventing bias vectors from updating during training.",
    "expected": "Both weights and biases should be updated during backpropagation.",
    "current": "Biases remain stuck at initial random values, limiting model capacity.",
    "files": "src/api/shared/systems/nn_framework/api.c (backprop())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Monitor bias values during training.\n2. Check if they change from initial values.",
    "hints": "Look for commented lines in the weight update section.",
    "solution": "Uncomment 'layer->bias_vect[j] -= lr * layer->delta[j];'"
  },
  {
    "id": 16,
    "title": "Memory Leak in Delta Vector",
    "description": "The free_mem function doesn't free the delta vector memory, leaking memory for every layer.",
    "expected": "All allocated memory should be properly freed.",
    "current": "Delta vectors are never freed, causing memory leaks.",
    "files": "src/api/shared/systems/nn_framework/api.c (free_mem())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Run the program multiple times.\n2. Monitor memory usage for leaks.",
    "hints": "Check if all allocated arrays are freed in the cleanup function.",
    "solution": "Uncomment 'free(layer->delta);'"
  },
  {
    "id": 17,
    "title": "Stale Error Reporting",
    "description": "Error is calculated after backpropagation, showing error after weights are updated instead of error that generated the gradients.",
    "expected": "Error should reflect the state before weight updates for accurate epoch reporting.",
    "current": "Reported error is for weights after update, not before.",
    "files": "src/api/shared/systems/nn_framework/api.c (main())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Monitor error values during training.\n2. Check if they correspond to pre-update or post-update state.",
    "hints": "Check the order of error calculation and backpropagation calls.",
    "solution": "Calculate error before calling backprop, then call backprop with that error."
  },
  {
    "id": 18,
    "title": "Wrong Norm in Cosine Similarity",
    "description": "Cosine similarity uses L1 norm (sum of components) instead of L2 norm (Euclidean length) for denominator calculation.",
    "expected": "Cosine similarity should use L2 norm (sqrt(sum of squares)) for correct calculation.",
    "current": "Similarity scores are mathematically incorrect due to wrong norm.",
    "files": "recommender.c (cosine_similarity())",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Test cosine similarity with known vectors.\n2. Verify if results match mathematical expectations.",
    "hints": "Check the norm calculation in the cosine similarity function.",
    "solution": "Change 'norma += a[i];' to 'norma += a[i] * a[i];' and same for normb"
  },
  {
    "id": 19,
    "title": "Skipping Rated Items in Prediction",
    "description": "The condition 'if (user_ratings[i] <= 1) continue;' incorrectly skips items rated 1-star along with unrated items.",
    "expected": "Only unrated items (rating 0) should be skipped, not low-rated items.",
    "current": "User's negative preferences (1-star ratings) are ignored in predictions.",
    "files": "recommender.c (predictor())",
    "difficulty": "medium",
    "points": 10,
    "steps": "1. Check predictions for items with 1-star ratings.\n2. Verify if they are considered in similarity calculations.",
    "hints": "Check the condition that skips items in the prediction loop.",
    "solution": "Change 'if (user_ratings[i] <= 1) continue;' to 'if (user_ratings[i] == 0) continue;'"
  },
  {
    "id": 20,
    "title": "Negative Similarity Handling in Weighted Average",
    "description": "The denominator uses raw similarity values instead of absolute values, causing issues with negative similarities.",
    "expected": "Denominator should use absolute values of similarities for stable weighted averages.",
    "current": "Negative similarities can make denominator small/negative, inflating predictions.",
    "files": "recommender.c (predictor())",
    "difficulty": "hard",
    "points": 15,
    "steps": "1. Test with datasets containing negative similarities.\n2. Check if predictions become unstable or extreme.",
    "hints": "Check how similarities are summed in the denominator calculation.",
    "solution": "Change 'sim_sum += sim;' to 'sim_sum += fabs(sim);'"
  }
]